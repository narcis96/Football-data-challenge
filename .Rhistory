for (i in 1:length(traincsv$ID))
{
array <- unlist(train[i,], use.names = FALSE)
array <- array[!is.na(array)]
matches[i,] <- array[3:4]
winners[i] <- array[5]
if(winners[i] == 3)
winners[i] <- 1
else if(winners[i] == 1)
winners[i] <- 3
}
for (index in indexes)
#for (i in 1:1)
{
dataSubsetProportion = .2;
print(index[1])
randomRows = index[1]:index[2]
trainingHoldoutSet = train[randomRows, ];#to test
trainingNonHoldoutSet = train[!(1:nrow(train) %in% randomRows), ];#to train
#gbmWithCrossValidation = gbm(formula = Response ~ .,
#                             distribution = "bernoulli",
#                             data = trainingNonHoldoutSet,
#                             n.trees = 2000,
#                             shrinkage = .1,
#                             n.minobsinnode = 200,
#                             cv.folds = 5,
#                             n.cores = 1)
}
setwd("/Users/gemenenarcis/Documents/MATLAB/Football-data-challenge/")
library(gbm)
traincsv <- read.csv("./trainSet/train.csv",header = TRUE,sep=",")
testcsv <- read.csv("./testSet/test.csv",header = TRUE,sep=",")
dates <- as.Date(traincsv$Date, "%Y-%m-%d")
years <- as.numeric(format(dates, "%Y"))
months <- format(dates, "%d")
uniqueYears <- sort.int(unique(years))
indexes <- matrix(0,2,length(uniqueYears) - 1)
for (i in 1:(length(uniqueYears) - 1))
{
year <- uniqueYears[i]
nextYear <- uniqueYears[i+1]
indx <- as.numeric(format(dates, "%Y")) == year & as.numeric(format(dates, "%m") >= 8)
indx <- indx | (as.numeric(format(dates, "%Y")) == nextYear & as.numeric(format(dates, "%m") <= 6))
indx <- which(indx == TRUE)
#attention!!the dates in train have to be sorted
indexes[1,i] <- min(indx);
indexes[2,i] <- max(indx);
print(length(indx))
print(indexes[2,i] - indexes[1,i] + 1)
}
matches <- matrix(0, 2, length(traincsv$ID));
winners <- matrix(0, 1, length(traincsv$ID));
for (i in 1:length(traincsv$ID))
{
array <- unlist(train[i,], use.names = FALSE)
array <- array[!is.na(array)]
matches[i,] <- array[3:4]
winners[i] <- array[5]
if(winners[i] == 3)
winners[i] <- 1
else if(winners[i] == 1)
winners[i] <- 3
}
for (index in indexes)
#for (i in 1:1)
{
dataSubsetProportion = .2;
print(index[1])
#  randomRows = index[1]:index[2]
# trainingHoldoutSet = train[randomRows, ];#to test
#trainingNonHoldoutSet = train[!(1:nrow(train) %in% randomRows), ];#to train
#gbmWithCrossValidation = gbm(formula = Response ~ .,
#                             distribution = "bernoulli",
#                             data = trainingNonHoldoutSet,
#                             n.trees = 2000,
#                             shrinkage = .1,
#                             n.minobsinnode = 200,
#                             cv.folds = 5,
#                             n.cores = 1)
}
#dataSubsetProportion = .2;
#randomRows = sample(1:nrow(train), floor(nrow(train) * dataSubsetProportion));#
#trainingHoldoutSet = train[randomRows, ];#to test
#trainingNonHoldoutSet = train[!(1:nrow(train) %in% randomRows), ];#to train
#gbmWithCrossValidation = gbm(formula = Response ~ .,
#                             distribution = "bernoulli",
#                             data = trainingNonHoldoutSet,
#                             n.trees = 2000,
#                             shrinkage = .1,
#                             n.minobsinnode = 200,
#                             cv.folds = 5,
#                             n.cores = 1)
#best  TreeForPrediction = gbm.perf(gbmWithCrossValidation)
#"%y-%d-%d"
#for(i in 1:length(train$HomeTeam))
#{
#array = unlist(train[i,], use.names = FALSE);
#array = array[!is.na(array)];
#print(array);
#}
setwd("/Users/gemenenarcis/Documents/MATLAB/Football-data-challenge/")
library(gbm)
traincsv <- read.csv("./trainSet/train.csv",header = TRUE,sep=",")
testcsv <- read.csv("./testSet/test.csv",header = TRUE,sep=",")
dates <- as.Date(traincsv$Date, "%Y-%m-%d")
years <- as.numeric(format(dates, "%Y"))
months <- format(dates, "%d")
uniqueYears <- sort.int(unique(years))
indexes <- matrix(0,2,length(uniqueYears) - 1)
for (i in 1:(length(uniqueYears) - 1))
{
year <- uniqueYears[i]
nextYear <- uniqueYears[i+1]
indx <- as.numeric(format(dates, "%Y")) == year & as.numeric(format(dates, "%m") >= 8)
indx <- indx | (as.numeric(format(dates, "%Y")) == nextYear & as.numeric(format(dates, "%m") <= 6))
indx <- which(indx == TRUE)
#attention!!the dates in train have to be sorted
indexes[1,i] <- min(indx);
indexes[2,i] <- max(indx);
print(length(indx))
print(indexes[2,i] - indexes[1,i] + 1)
}
matches <- matrix(0, length(traincsv$ID), 2);
winners <- matrix(0, length(traincsv$ID), 1);
for (i in 1:length(traincsv$ID))
{
array <- unlist(train[i,], use.names = FALSE)
array <- array[!is.na(array)]
matches[i,] <- array[3:4]
winners[i] <- array[5]
if(winners[i] == 3)
winners[i] <- 1
else if(winners[i] == 1)
winners[i] <- 3
}
for (index in indexes)
#for (i in 1:1)
{
dataSubsetProportion = .2;
print(index[1])
#  randomRows = index[1]:index[2]
# trainingHoldoutSet = train[randomRows, ];#to test
#trainingNonHoldoutSet = train[!(1:nrow(train) %in% randomRows), ];#to train
#gbmWithCrossValidation = gbm(formula = Response ~ .,
#                             distribution = "bernoulli",
#                             data = trainingNonHoldoutSet,
#                             n.trees = 2000,
#                             shrinkage = .1,
#                             n.minobsinnode = 200,
#                             cv.folds = 5,
#                             n.cores = 1)
}
for (index in indexes)
#for (i in 1:1)
{
dataSubsetProportion = .2;
randomRows = index[1]:index[2]
trainingHoldoutSet = train[randomRows, ];#to test
trainingNonHoldoutSet = train[!(1:nrow(train) %in% randomRows), ];#to train
gbmWithCrossValidation = gbm(formula = Response ~ .,
distribution = "bernoulli",
data = trainingNonHoldoutSet,
n.trees = 2000,
shrinkage = .1,
n.minobsinnode = 200,
cv.folds = 5,
n.cores = 1)
}
for (index in indexes)
#for (i in 1:1)
{
dataSubsetProportion = .2;
randomRows = index[1]:index[2]
#trainingHoldoutSet = train[randomRows, ];#to test
#trainingNonHoldoutSet = train[!(1:nrow(train) %in% randomRows), ];#to train
#gbmWithCrossValidation = gbm(formula = Response ~ .,
#                            distribution = "bernoulli",
#                           data = trainingNonHoldoutSet,
#                          n.trees = 2000,
#                         shrinkage = .1,
#                        n.minobsinnode = 200,
#                       cv.folds = 5,
#                      n.cores = 1)
}
indexes
for (i in 1:ncol(indexes))
{
dataSubsetProportion = .2;
randomRows = index[1,i]:index[2,i]
}
for (i in 1:ncol(indexes))
{
dataSubsetProportion = .2;
randomRows = indexes[1,i]:indexes[2,i]
#trainingHoldoutSet = train[randomRows, ];#to test
#trainingNonHoldoutSet = train[!(1:nrow(train) %in% randomRows), ];#to train
#gbmWithCrossValidation = gbm(formula = Response ~ .,
#                            distribution = "bernoulli",
#                           data = trainingNonHoldoutSet,
#                          n.trees = 2000,
#                         shrinkage = .1,
#                        n.minobsinnode = 200,
#                       cv.folds = 5,
#                      n.cores = 1)
}
for (i in 1:ncol(indexes))
{
dataSubsetProportion = .2;
randomRows = indexes[1,i]:indexes[2,i]
print(randomRows)
#trainingHoldoutSet = train[randomRows, ];#to test
#trainingNonHoldoutSet = train[!(1:nrow(train) %in% randomRows), ];#to train
#gbmWithCrossValidation = gbm(formula = Response ~ .,
#                            distribution = "bernoulli",
#                           data = trainingNonHoldoutSet,
#                          n.trees = 2000,
#                         shrinkage = .1,
#                        n.minobsinnode = 200,
#                       cv.folds = 5,
#                      n.cores = 1)
}
for (i in 1:1)#ncol(indexes))
{
dataSubsetProportion = .2;
rows = indexes[1,i]:indexes[2,i]
trainingHoldoutSet = train[rows, ];#to test
trainingNonHoldoutSet = train[!(1:nrow(train) %in% rows), ];#to train
gbmWithCrossValidation = gbm(formula = Response ~ .,
distribution = "bernoulli",
data = trainingNonHoldoutSet,
n.trees = 2000,
shrinkage = .1,
n.minobsinnode = 200,
cv.folds = 5,
n.cores = 1)
}
trainingNonHoldoutSet
for (i in 1:1)#ncol(indexes))
{
dataSubsetProportion = .2;
rows = indexes[1,i]:indexes[2,i]
trainingHoldoutSet = matches[rows, ];#to test
trainingNonHoldoutSet = matches[!(1:nrow(train) %in% rows), ];#to train
gbmWithCrossValidation = gbm(formula = Response ~ .,
distribution = "bernoulli",
data = trainingNonHoldoutSet,
n.trees = 2000,
shrinkage = .1,
n.minobsinnode = 200,
cv.folds = 5,
n.cores = 1)
}
head(data.frame("Actual" = matches[1,],
"PredictedProbability" = matches[2,]))
matches
head(data.frame("Actual" = matches[,1],
"PredictedProbability" = matches[,2]))
data.frame("Actual" = matches[,1],
"PredictedProbability" = matches[,2])
data.frame("Actual" = train$HomeTeam,
"PredictedProbability" = train$AwayTeam)
train$HomeTeam[2]
train$HomeTeam[2:10]
train[2:10,3:4]
trainingHoldoutSet = train[rows,3:4];
trainingHoldoutSet
length(trainingHoldoutSet)
nrow(trainingHoldoutSet)
for (i in 1:1)#ncol(indexes))
{
dataSubsetProportion = .2;
rows = indexes[1,i]:indexes[2,i]
trainingHoldoutSet = train[rows,3:4];
trainingNonHoldoutSet = train[!(1:nrow(train)), 3:4];#to train
print(nrow(trainingHoldoutSet))
print(nrow(trainingNonHoldoutSet))
#gbmWithCrossValidation = gbm(formula = Response ~ .,
#                            distribution = "bernoulli",
#                           data = trainingNonHoldoutSet,
#                          n.trees = 2000,
#                         shrinkage = .1,
#                        n.minobsinnode = 200,
#                       cv.folds = 5,
#                      n.cores = 1)
}
for (i in 1:1)#ncol(indexes))
{
dataSubsetProportion = .2;
rows = indexes[1,i]:indexes[2,i]
trainingHoldoutSet = train[rows,3:4];
trainingNonHoldoutSet = train[!(1:nrow(train)%in% rows), 3:4];#to train
print(nrow(trainingHoldoutSet))
print(nrow(trainingNonHoldoutSet))
#gbmWithCrossValidation = gbm(formula = Response ~ .,
#                            distribution = "bernoulli",
#                           data = trainingNonHoldoutSet,
#                          n.trees = 2000,
#                         shrinkage = .1,
#                        n.minobsinnode = 200,
#                       cv.folds = 5,
#                      n.cores = 1)
}
for (i in 1:1)#ncol(indexes))
{
dataSubsetProportion = .2;
rows = indexes[1,i]:indexes[2,i]
trainingHoldoutSet = train[rows,3:4];
trainingNonHoldoutSet = train[!(1:nrow(train) %in% rows), 3:4];#to train
print(nrow(trainingHoldoutSet))
print(nrow(trainingNonHoldoutSet))
#gbmWithCrossValidation = gbm(formula = Response ~ .,
#                            distribution = "bernoulli",
#                           data = trainingNonHoldoutSet,
#                          n.trees = 2000,
#                         shrinkage = .1,
#                        n.minobsinnode = 200,
#                       cv.folds = 5,
#                      n.cores = 1)
}
for (i in 1:1)#ncol(indexes))
{
dataSubsetProportion = .2;
rows = indexes[1,i]:indexes[2,i]
trainingHoldoutSet = train[rows,3:4];
trainingNonHoldoutSet = train[!(1:nrow(train) %in% rows), 3:4];#to train
print(nrow(trainingHoldoutSet))
print(nrow(trainingNonHoldoutSet))
gbmWithCrossValidation = gbm(formula = Response ~ .,
distribution = "bernoulli",
data = trainingNonHoldoutSet,
n.trees = 2000,
shrinkage = .1,
n.minobsinnode = 200,
cv.folds = 5,
n.cores = 1)
}
for (i in 1:1)#ncol(indexes))
{
dataSubsetProportion = .2;
rows = indexes[1,i]:indexes[2,i]
trainingHoldoutSet = train[rows,3:4];
trainingNonHoldoutSet = train[!(1:nrow(train) %in% rows), 3:4];#to train
print(nrow(trainingHoldoutSet))
print(nrow(trainingNonHoldoutSet))
gbmWithCrossValidation = gbm(formula = train$FTR ~ .,
distribution = "bernoulli",
data = trainingNonHoldoutSet,
n.trees = 2000,
shrinkage = .1,
n.minobsinnode = 200,
cv.folds = 5,
n.cores = 1)
}
train[rows,3:4];#to test
rows
train[rows,3:4];#to test
for (i in 1:1)#ncol(indexes))
{
dataSubsetProportion = .2;
rows = indexes[1,i]:indexes[2,i]
trainingHoldoutSet = train[rows,3:4];#to test
trainingNonHoldoutSet = train[!(1:nrow(train) %in% rows), 3:4];#to train
print(nrow(trainingHoldoutSet))
print(nrow(trainingNonHoldoutSet))
gbmWithCrossValidation = gbm(formula = train$FTR ~ .,
distribution = "bernoulli",
data = trainingHoldoutSet,
n.trees = 2000,
shrinkage = .1,
n.minobsinnode = 200,
cv.folds = 5,
n.cores = 1)
}
for (i in 1:1)#ncol(indexes))
{
dataSubsetProportion = .2;
rows = indexes[1,i]:indexes[2,i]
trainingHoldoutSet = train[1:2,3:4];#to test
#  trainingNonHoldoutSet = train[!(1:nrow(train) %in% rows), 3:4];#to train
trainingNonHoldoutSet = train[1:2,3:4]
print(nrow(trainingHoldoutSet))
print(nrow(trainingNonHoldoutSet))
gbmWithCrossValidation = gbm(formula = train$FTR ~ .,
distribution = "bernoulli",
data = trainingNonHoldoutSet,
n.trees = 2000,
shrinkage = .1,
n.minobsinnode = 200,
cv.folds = 5,
n.cores = 1)
}
trainingNonHoldoutSet
for (i in 1:1)#ncol(indexes))
{
dataSubsetProportion = .2;
rows = indexes[1,i]:indexes[2,i]
trainingHoldoutSet = train[1:2,3:4];#to test
#  trainingNonHoldoutSet = train[!(1:nrow(train) %in% rows), 3:4];#to train
trainingNonHoldoutSet = train[1:2,3:4]
print(nrow(trainingHoldoutSet))
print(nrow(trainingNonHoldoutSet))
gbmWithCrossValidation = gbm(formula = train$FTR[1:2] ~ .,
distribution = "bernoulli",
data = trainingNonHoldoutSet,
n.trees = 2000,
shrinkage = .1,
n.minobsinnode = 200,
cv.folds = 5,
n.cores = 1)
}
for (i in 1:1)#ncol(indexes))
{
dataSubsetProportion = .2;
rows = indexes[1,i]:indexes[2,i]
trainingHoldoutSet = train[1:2,3:4];#to test
trainingNonHoldoutSet = train[!(1:nrow(train) %in% rows), 3:4];#to train
print(nrow(trainingHoldoutSet))
print(nrow(trainingNonHoldoutSet))
gbmWithCrossValidation = gbm(formula = train$FTR[!(1:nrow(train) %in% rows)] ~ .,
distribution = "bernoulli",
data = trainingNonHoldoutSet,
n.trees = 2000,
shrinkage = .1,
n.minobsinnode = 200,
cv.folds = 5,
n.cores = 1)
}
help("gbm")
setwd("/Users/gemenenarcis/Documents/MATLAB/Football-data-challenge/")
library(gbm)
traincsv <- read.csv("./trainSet/train.csv",header = TRUE,sep=",")
testcsv <- read.csv("./testSet/test.csv",header = TRUE,sep=",")
dates <- as.Date(traincsv$Date, "%Y-%m-%d")
years <- as.numeric(format(dates, "%Y"))
months <- format(dates, "%d")
uniqueYears <- sort.int(unique(years))
indexes <- matrix(0,2,length(uniqueYears) - 1)
for (i in 1:(length(uniqueYears) - 1))
{
year <- uniqueYears[i]
nextYear <- uniqueYears[i+1]
indx <- as.numeric(format(dates, "%Y")) == year & as.numeric(format(dates, "%m") >= 8)
indx <- indx | (as.numeric(format(dates, "%Y")) == nextYear & as.numeric(format(dates, "%m") <= 6))
indx <- which(indx == TRUE)
#attention!!the dates in train have to be sorted
indexes[1,i] <- min(indx);
indexes[2,i] <- max(indx);
print(length(indx))
print(indexes[2,i] - indexes[1,i] + 1)
}
matches <- matrix(0, length(traincsv$ID), 2);
winners <- matrix(0, length(traincsv$ID), 1);
for (i in 1:length(traincsv$ID))
{
array <- unlist(train[i,], use.names = FALSE)
array <- array[!is.na(array)]
matches[i,] <- array[3:4]
winners[i] <- array[5]
if(winners[i] == 3)
winners[i] <- 1
else if(winners[i] == 1)
winners[i] <- 3
}
#data.frame("Actual" = train$HomeTeam,
#          "PredictedProbability" = train$AwayTeam)
for (i in 1:1)#ncol(indexes))
{
dataSubsetProportion = .2;
rows = indexes[1,i]:indexes[2,i]
trainingNonHoldoutSet = train[!(1:nrow(train) %in% rows), 3:4];#to train
print(nrow(trainingHoldoutSet))
print(nrow(trainingNonHoldoutSet))
gbmWithCrossValidation = gbm(formula = train$FTR[!(1:nrow(train) %in% rows)] ~ .,
distribution = "multinomial",
data = trainingNonHoldoutSet,
n.trees = 2000,
shrinkage = .1,
n.minobsinnode = 200,
cv.folds = 5,
n.cores = 1)
}
bestTreeForPrediction = gbm.perf(gbmWithCrossValidation)
bestTreeForPrediction
for (i in 1:1)#ncol(indexes))
{
dataSubsetProportion = .2;
rows = indexes[1,i]:indexes[2,i]
trainingNonHoldoutSet = train[!(1:nrow(train) %in% rows), 3:4];#to train
print(nrow(trainingHoldoutSet))
print(nrow(trainingNonHoldoutSet))
gbmWithCrossValidation = gbm(formula = train$FTR[!(1:nrow(train) %in% rows)] ~ .,
distribution = "multinomial",
data = trainingNonHoldoutSet,
n.trees = 2000,
shrinkage = .1,
n.minobsinnode = 200,
cv.folds = 5,
n.cores = 1)
bestTreeForPrediction = gbm.perf(gbmWithCrossValidation)
gbmHoldoutPredictions = predict(object = gbmWithCrossValidation,
newdata = trainingHoldoutSet,
n.trees = bestTreeForPrediction,
type = "response")
gbmNonHoldoutPredictions = predict(object = gbmWithCrossValidation,
newdata = trainingNonHoldoutSet,
n.trees = bestTreeForPrediction,
type = "response")
}
print(paste(LogLossBinary(train$Response[randomRows], gbmHoldoutPredictions),
"Holdout Log Loss"))
print(paste(LogLossBinary(train$Response[!(1:nrow(train) %in% randomRows)], gbmNonHoldoutPredictions),
"Non-Holdout Log Loss"))
